{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OrganStopClassifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN8w+7M4YQuOavzQxrdXmPg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markwreinke/OrganStopClassifier/blob/main/OrganStopClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjZ3HavYVrTF"
      },
      "source": [
        "This is going to be the code for a Organ Stop Classifier NN.\n",
        "\n",
        "Here is the current gameplan:\n",
        "\n",
        "\n",
        "1.   Import training and test sets\n",
        "2.   Run labeled training data through NN\n",
        "3.   Run test data through NN and compute accuracy\n",
        "\n",
        "I need to figure out how to format the data so that it can be put into a data loader. Unless if I were to figure out how to make my own dataloader, and have each set of data correspond to a txt file of proper labels. I might be able to do this by naming the wav files in a way that corresponds to its label in the txt file. Then I could figure out how to parse and iterate through that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7o517EoVkZX"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE = False\n",
        "torchaudio.set_audio_backend(\"sox_io\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKHJSKOLenVu"
      },
      "source": [
        "samplesWaveforms = []\n",
        "sample_rates = []\n",
        "\n",
        "\n",
        "\n",
        "datasetDirName = \"\"\n",
        "i = 0\n",
        "for filename in os.listdir(datasetDirName):\n",
        "  if filename.endswith(\".wav\"):\n",
        "    samplesWaveforms[i], sample_rates[i] = torchaudio.load(filename)\n",
        "    i++\n",
        "  else:\n",
        "      continue\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCZt2LdBeCsO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}