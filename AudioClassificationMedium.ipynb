{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AudioClassificationMedium.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMbFOPcUs+v1Vz5UUD/3wgX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markwreinke/OrganStopClassifier/blob/main/AudioClassificationMedium.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGJX6CnV53VA"
      },
      "source": [
        "This is a tutorial taken from https://medium.com/@hasithsura/audio-classification-d37a82d6715 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VfXLoXQucv6"
      },
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "# This function give a mel spectrogram of the given file\n",
        "#  sr=None -> Librosa should use the native sampling rate of 44.1KHz to load the audio data instead of the default of 22.05KHz\n",
        "#  Next the first 5 seconds of given audio is extracted\n",
        "#  2048 samples are chosen for each window (about 46ms)\n",
        "#  A hop_length of 512 samples is chose, meaning the window is moved by skipping 512 samples to get the next time frame\n",
        "#  The number of mel filters is 128, makes the height of the spectrogram image 128\n",
        "#  fmin and fmax are the lowest and highest frequencies\n",
        "def get_melspectrogram_db(file_path, sr=None, n_fft=2048, hop_length=512, n_mels=128, fmin=20, fmax=8300, top_db=80):\n",
        "  wav, sr = librosa.load(file_path, sr=sr)\n",
        "  if wav.shape[0]<5*sr:\n",
        "     wav=np.pad(wav,int(np.ceil((5*sr-wav.shape[0])/2)),mode='reflect')\n",
        "  else:\n",
        "    wav=wav[:5*sr]\n",
        "\n",
        "  spec=librosa.feature.melspectrogram(wav, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, fimin=fmin, fmax=fmax)\n",
        "\n",
        "  #Librosa squares the magnitude of the spectrogram when constructing Mel Spectrogram, so we use power_to_db to convert power magnitude to decipels. top_db is used to threshold the output.\n",
        "  spec_db=librosa.power_to_db(spec, top_db=top_db)\n",
        "  return spec_db"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUui5w8H4djV"
      },
      "source": [
        "# Here we are going to conver Spectrogram into an image\n",
        "def spec_to_image(spec, eps=1e-6):\n",
        "  mean = spec.mean()\n",
        "  std = spec.std()\n",
        "  spec_norm = (spec - mean) / (std + eps)\n",
        "  spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
        "  spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
        "  spec_scaled = spec_scaled.astype(np.uint8)\n",
        "  return spec_scaled\n",
        "\n",
        "  # This spectrogram is normalized using z score normalization and scled using min-max scaling so its values lie between 0 and 255"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdBLjGXS5_jo"
      },
      "source": [
        "# This is building the model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}